{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = \"../test data/sample 1.pdf\"\n",
    "loader = UnstructuredPDFLoader(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()\n",
    "for doc in data:\n",
    "    data = doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Convert PDF to images\n",
    "doc_path = \"../test data/sample 1.pdf\"\n",
    "\n",
    "_, ext = os.path.splitext(doc_path)\n",
    "\n",
    "if ext == \".pdf\":\n",
    "    images = convert_from_path(doc_path)\n",
    "    # Iterate over the images and extract text\n",
    "    for i in range(len(images)):\n",
    "        text = pytesseract.image_to_string(images[i], lang=\"eng\")\n",
    "        print(text)\n",
    "else:\n",
    "    print(\"file is not a pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "ground_truth = data\n",
    "\n",
    "extracted_text = text\n",
    "\n",
    "print(similarity(ground_truth, extracted_text))  ## 0.9637987776210625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "# Text cleaning\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \")  # replace newline characters with space\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
    "    text = text.strip()  # remove leading and trailing whitespace\n",
    "    return text\n",
    "\n",
    "\n",
    "cleaned_text = clean_text(text=extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1 import SecretStr\n",
    "\n",
    "api_key = SecretStr(\"...\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that Identifying and extracting entities like names, dates, Address, email, Phone Number, etc. Extracting relationships between entities. Summarizing key information from the document.\",\n",
    "    ),\n",
    "    (\"human\", cleaned_text),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ai_msg.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
